
[DEFAULTS]

#name of the run
name = stable_audio_tools

# the batch size
batch_size = 1

# number of GPUs to use for training
num_gpus = 1

# number of nodes to use for training
num_nodes = 1 

# Multi-GPU strategy for PyTorch Lightning
strategy = "deepspeed"

# Precision to use for training
precision = "16-mixed"

# number of CPU workers for the DataLoader
num_workers = 1

# the random seed
seed = 42

# Batches for gradient accumulation
accum_batches = 1

# Number of steps between checkpoints
; checkpoint_every = 10000                              
checkpoint_every = 100
                     
# trainer checkpoint file to restart training from
ckpt_path = ''

# model checkpoint file to start a new training run from
pretrained_ckpt_path = './model.ckpt'

# Checkpoint path for the pretransform model if needed
pretransform_ckpt_path = ''

# configuration model specifying model hyperparameters
model_config = 'model_config.json'

# configuration for datasets
dataset_config = 'dataset_config.json'

# directory to save the checkpoints in
save_dir = 'checkpoints'

# gradient_clip_val passed into PyTorch Lightning Trainer
gradient_clip_val = 0.0

# remove the weight norm from the pretransform model
remove_pretransform_weight_norm = ''

# S3 configuration for uploading checkpoints and demos
s3_checkpoint_bucket = 'deep-fadr'
s3_checkpoint_prefix = 'robert/stable-audio-open/test/checkpoints'
s3_demo_bucket = 'deep-fadr'
s3_demo_prefix = 'robert/stable-audio-open/test/demos'

# Checkpoint upload mode: 'single_file' or 'full_directory'
s3_checkpoint_mode = 'single_file'

# Delete local checkpoints after successful S3 upload to save storage
s3_delete_after_upload = true